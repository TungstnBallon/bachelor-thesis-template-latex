\chapter{Evaluation}
\label{chapter:Evaluation}

The focus of the evaluation will be on the different runtimes of the various possible backends. These will be evaluated by running varouis prepared Jayvee models on one underlying dataset.

\section{Data source}
\label{section:data_source}

\subsection{Requirements}
%TODO: why not functional vs non-functional
\label{subsection:data_source_requirements}
\begin{enumerate}
	\item The dataset has to be available in a csv format, because the interpreter can only create tables from csv data.
	\item Jayvee tables can only contain boolean, text, integer and decimal values, so data other than that (e.g. dates) will not be parsed and represented as text.
	\item The dataset should be a minimum of $800\text{MB}$, to make the backend's differences in speed visible.
	\item The dataset should not be larger than $3\text{GB}$, because open-datasets are usually not that big. %FIXME: citation needed +  everything.
	\item The dataset must have an open license.% TODO: explanation. %TODO: list open licences
\end{enumerate}

The polars backend cannot transform dates, so the dataset must contain numbers or booleans.

\subsection{Chosen Dataset}
The chosen dataset is called "Brewery Operations and Market Analysis" and not based on any real wold data, but rather generated by a python script \autocite{dataset}.

\subsubsection{Biases}

\section{Parameters}
\label{section:parameters}

\section{Extended Capabilities}
\label{section:jv_limits}

When using the one-block \TODO: give proper name
optimization, the jayvee interpreters capabilites are enhanced, because it does not have the nodejs limitations anymore, when parsing the csv.
\begin{itemize}
	\item Files larger than 2GB
	\item Csv values can contain newlines, because the string is not split before parsing csv
\end{itemize}

\section{evaluation tool}

\section{the numbers}
%TODO: pie chart of supported transfrorms
%TODO: stuff that is not supported by jayvee
