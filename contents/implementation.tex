\chapter{Implementation}
\label{chapter:Implementation}

\section{Type Conversion}
\label{subsection:TypeConversion}
In order to convert Polars' DataType to a Jayvee ValueType, the following method is added is added to the \Verb|ValueTypeProvider| class.
\mint{typescript}|fromPolarsDType(dtype: polars.DataType): ValueType|
This method uses \Verb|DataType.equals| to compare DataTypes.
Many DataTypes result in the same ValueType, for example, both \Verb|polars.Float32| and \Verb|polars.Float64| return \Verb|Decimal|.
The DataTypes \Verb|Categorical|, \Verb|Date|, \Verb|DateTime|, \Verb|List|, \Verb|Null| and \Verb|Struct| do not have a direct ValueType equivalent and throw an error.

To convert in the opposite direction, the \mint{typescript}{toPolarsDataType(): polars.DataType | undefined} method is added to the \Verb|ValueType| interface.
Unsupported ValueTypes are \Verb|EmptyCollection|, \Verb|Collection| if the inner ValueType is supported, \Verb|ValueTypeAssignment|, \Verb|Transform|, \Verb|Regex|, \Verb|Constraint|, \Verb|CellRange|.
Their implementation of \Verb|toPolarsDataType| returns \Verb|undefined|.

Often polars methods return \Verb|any| where the interpeter expects \Verb|InternalValueRepresentation|.
To narrow down the \Verb|any| type we expand the existing typeguards defined in \Verb|libs/language-server/src/lib/ast/expressions/typeguards.ts| to handle inputs with \Verb|unknown| type.
\Verb|string|, \Verb|number| and \Verb|boolean| use \Verb|typeof|.
\Verb|RegExp| uses \Verb|instanceof|.
\Verb|CellRangeLiteral|, \Verb|ConstraintDefinition|, \Verb|ValuetypeAssignment|, \Verb|BlockTypeProperty| and \Verb|TransformDefinition| use langium generated typeguards.
\Verb|AtomicInternalValueRepresentation| returns true if any of the above returns true.
\Verb|Array<InternalValueRepresentation>| uses \Verb|Array.isArray| and verifies every value of the array to be \Verb|InternalValueRepresentation|.
\Verb|InternalValueRepresentation| is true if either \Verb|Array<InternalValueRepresentation>| or \Verb|AtomicInternalValueRepresentation|.

\section{Table}
\subsection{abstract Table}
The table implementation is located in \Verb{libs/execution/src/lib/types/io-types/table.ts}.
To increase clarity, the abstract \Verb|TableColumn| class and its subclasses \Verb|PolarsTableColumn| and \Verb|TsTableColumn| are moved into their own file \Verb|table-column.ts|.

\subsubsection{changes compared to old table}
\label{subssubsection:impl:old_vs_new}
The old \Verb|addColum| method used to modify its table instance to add the column.
The new \Verb|withColum| method returns a new Table instance, that includes the new column.
However, the interpreter has to keep using \Verb|addColumn| when working with \Verb|TsTable|, because other behavoir would skew the evaluation results.

- leads to less mutations, so it's better for parallel execution %TODO: citation

\subsection{PolarsTable}
As described in \ref{subsection:arch:polarstable}, follows the adapter pattern and \Verb|PolarsTable| wraps \Verb|polars.DataFrame|.
This leads to several wrapper methods, that call \Verb|DataFrame| methods and return that result:
\Verb|writeIpc|, \Verb|writeIpcTo|, \Verb|withColumn|, \Verb|withColumnFromInternal|, \Verb|nRows|, \Verb|nColumns|, \Verb|clone| and \Verb|toString|.

\Verb|getTypes| gets the \Verb|DataFrame|'s types, an array of DataTypes, and applies \Verb|fromPolarsDType| (\ref{subsection:TypeConversion}).

\Verb|generateInsertValuesStatement| converts the dataframe to a row-oriented, two-dimensional array, containing \Verb|any| values.
Utilise the new typeguards descibed in \ref{subsection:TypeConversion}, to ensure these are values of type \Verb|InternalValueRepresentation|.
Convert each cell into its \ac{SQL} value with \Verb|SQLValueRepresentationVisitor|.
If the cell has no \ac{SQL} representation, use \Verb|'NULL'|.
\mintinline{typescript}|Array<string>.join| and template strings are used to combine the cells into rows and the rows into the final statement.

\Verb|generateCreateTableStatement| uses \Verb|SQLColumnTypeVisitor| to convert ValueTypes to \ac{SQL}, e. g. \Verb|decimal| becomes \Verb|'real'|.

\Verb|hasColumn| does not have a direct equivalent \Verb|DataFrame| method.
The method uses \Verb|DataFrame.getColumn| and returns \Verb|true| if the call succeeds, \Verb|false| if it throws an exception.

\Verb|columns| and \Verb|getColumn| both face the challenge, that \Verb|Series|, which is returned by \Verb|DataFrame.getColumn|, does not include the ValueType required by the \Verb|PolarsTableColumn| constructor.
They solve this by using the \Verb|this.valueTypeProvider.fromPolarsDType| conversion method.

\subsubsection{TsTable}
We will only describe new functionality, as this class only exists to preserve the original implementaiton.

\Verb|withColumn| uses the \Verb|clone| method and then adds the column to that new table using \Verb|addColumn|.

\Verb|clone| clones every column individually, puts them into a new map, and then wraps that map in a new \Verb|TsTable| object.

\section{TableColumn}
\subsection{polarsTableColumn}
\Verb|PolarsTableColumn| is a thin wrapper around \Verb|polars.Series|.
It does't have any methods, that aren't getters or wrappers around equivalent \Verb|Series| methods.

\subsubsection{TsTableColumn}
All properties are prefixed with an underscore to prevent a naming conflict between the property and their getter / setter.

\Verb|clone| requires a \emph{deep clone} of the \Verb|_values| array.
Bases on our experience, the usual way to accomplish this is the global \Verb|structuredClone| function.
This approach caused the program to crash at runtime.
We suspect the cause has to do with limitations of \Verb|structuredClone| described by \textcite{js:docs:structuredClone}.
This problem was solved by serializing the column to \ac{JSON}, and parsing it again, creating deep copies in the process.
The typegards from \ref{subsection:TypeConversion} were used to regain the type infromation lost by this process.

\Verb|push| checks if the new element is a valid for the column's ValueType using \Verb|ValueType.isInternalValueRepresentation| before pushing.

\Verb|drop| uses \Verb|Array<T>.splice| to remove one element from the value array.


\section{new executors} %FIXME
\subsection{Selecting the correct block executor} %FIXME
\label{subsection:createBlockExecutor}
\Verb|getExecutorForBlockType| in \Verb|libs/execution/src/lib/extension.ts| is modified to look for a different blocktype than its parameter specifies.
Refer to \ref{fig:uml:getExecutorForBlockType} for a diagram. %FIXME: what diagram
\begin{figure}
	\begin{plantuml}
		@startuml
		!pragma useVerticalIf on
		start
		if (blockTypeName === 'TableInterpreter') then (true)
		if (usePolars) then (true)
		:blockTypeName = 'PolarsTableInterpreter';
		else (false)
		:blockTypeName = 'TsTableInterpreter';
		endif
		elseif (blockTypeName === 'TableTransformer') then (true)
		if (usePolars) then (true)
		:blockTypeName = 'PolarsTableTransformer';
		else (false)
		:blockTypeName = 'TsTableTransformer';
		endif
		elseif (blockTypeName === 'SQLiteLoader') then (true)
		if (useRusqlite) then (true)
		:blockTypeName = 'RustTableTransformer';
		elseif (usePolars) then (true)
		:blockTypeName = 'PolarsTableTransformer';
		else (false)
		:blockTypeName = 'TsTableTransformer';
		endif
		endif
		stop
		@enduml
	\end{plantuml}
	\caption{How we pick the right blocktype name}
	\label{fig:uml:getExecutorForBlockType}
\end{figure}


\subsection{TableInterpreterExecutor} %TODO
\label{section:tableinterpreterexecutor}

\Verb|TableInterpreterExecutor| is implemented in \Verb|libs/extensions/tabular/exec/src/lib/table-interpreter-executor.ts|.
This file also contains the function
\mint{typescript}|toPolarsDataTypeWithLogs(valueType: ValueType, logger: Logger): polars.DataType|
Its purpose is to convert Polars DataTypes to Jayvee ValueTypes, replacing unsupported ValueTypes with a fallack (\ref{lst:toPolarsDataTypeWithLogs}).
log unsupported ValueTypes with \Verb|logger.logErr| and return the fallback \Verb|pl.Utf8|.
TODO?: circular imports?

\begin{listing}
	\begin{minted}{python}
def toPolarsDataTypeWithLogs(valueType, logger):
	dataType = valueType.toPolarsDataType()
	if dataType is undefined:
		... # Log the error using logger
		return polars.Utf8
	return dataType
	\end{minted}
	\caption{Pseudocode of the \Verb|toPolarsDataTypeFunction|}
	\label{lst:toPolarsDataTypeWithLogs}
\end{listing}

% \begin{figure}
% 	\begin{plantuml}
% 		@startuml
% 		interface ColumnDefinitionEntry {
% 				sheetColumnIndex: number
% 				columnName: string
% 				valueType: ValueType
% 				astNote: ValuetypeAssignment
% 			}
% 		@enduml
% 	\end{plantuml}
% 	\caption{\Verb|ColumnDefinitionEntry|}\label{fig:uml:ColumnDefinitionEntry}
% \end{figure}

\Verb|deriveColumnDefinitionEntriesWithoutHeader|, \Verb|deriveColumnDefinitionEntriesFromHeader| and \Verb|parseAndValidateValue| remain unchanged because they do not rely on the table implementation.

% - deriveColumnDefinitionEntriesWithoutHeader
% - uses the definitions from the schema property of the TableInterpreter block
% - return ColumnDefinitionEntry containing columnname and valueType
%
% - deriveColumnDefinitionEntriesFromHeader
% - use names in the header row to find column index of the header
% - if name isn't in the header row the column is ignored
% - otherwise same behavior as deriveColumnDefinitionEntriesWithoutHeader

\Verb|doExecute| only preprocesses the block's properties and leaves the implementation specifics to \Verb|TableInterpreterExecutor|'s subclasses (\ref{lst:tableInterpreter:doExecute}).
\begin{listing}
	\begin{minted}{python}
def doExecute(inputSheet, context):
	header = context.get("header")
	columnDefinitions = context.get("columns")
	if header:
		columnEntries = deriveColumnDefinitionEntriesFromHeader(columnDefinitions, inputSheet.header_row)
	else:
		columnEntries = deriveColumnDefinitionEntriesWithoutHeader(columnDefinitions)

	return constructAndValidateTable(
		inputSheet,
		header,
		columnEntries,
		context
	)
	\end{minted}
	\caption{Pseudocode for \Verb|TableInterpreter.doExecute|}
	\label{lst:tableInterpreter:doExecute}
\end{listing}

\subsubsection{PolarsTableInterpreterExecutor}
\label{subsubsection:polarstableinterpreterexecutor}
The static attribute \Verb|type| set to \Verb|'PolarsTableInterpreter'|.
This the value the interpreter checks when looking for block executors.
Because we manipulated the selection process in \ref{subsection:createBlockExecutor}, the interpreter is looking for \Verb|PolarsTableInterpreter| instead of \Verb|TableInterpreter|.

We outline the behavior of \Verb|constructAndValidateTable| (\ref{lst:polarsTableInterpreter:constructTable}) and \Verb|constructSeries| (\ref{lst:polarsTableInterpreter:constructSeries}) pseudocode examples in the respective listings.
\begin{listing}
	\begin{minted}{python}
def constructAndValidateTable(sheet, header, columnEntries, context):
	rows = sheet.getData()
	# rows is a row-oriented, two dimensional array of strings
	if header:
		... # Skip first row
	series = []  # Empty list
	for entry in columnEntries:
		s = this.constructSeries(rows, entry, context)
		series.add(s)
	dataFrame = polars.DataFrame(series)
	return new PolarsTable(dataFrame, context.valueTypeProvider)
	\end{minted}
	\caption{}
	\label{lst:polarsTableInterpreter:constructTable}
\end{listing}
\begin{listing}
	\begin{minted}{python}
def constructSeries(rows, columnEntry, context):
	valueType = columnEntry.valueType
	dataType = toPolarsTypeWithLogs(valueType, context.logger)
	values = []  # Empty list
	for row in rows:
		cell = row[columnEntry.sheetColumnIndex]
		value = this.parseAndValidateValue(cell, valueType, context)
		columnData.add(value)

	return polars.Series(columnEntry.ColumnName, values, dataType)
	\end{minted}
	\caption{}
	\label{lst:polarsTableInterpreter:constructSeries}
\end{listing}

% \subsubsection{TsTableInterpreter}
% - many of the TableInterpreter functions used to be here
% - no functionality added or changed

\section{FileToTableIntepreter}
The blocktype definition located at \Verb|libs/language-server/src/stdlib/builtin-block-types/FileToTableInterpreter.jv| defines the following properties:
Since \Verb|FileToTableInterpreter| is a combination of \Verb|TextFileInterpreter|, \Verb|CSVInterpreter| and \Verb|TableInterpreter|, their properties and default values are copied into the definition.
One property is no longer supported:
\Verb|TextFileInterpreter|'s \Verb|lineBreak|: splitting lines is handled by Polars, which does not support linebreaks based on a \ac{regex}.

\subsection{FileToTableIntepreterExecutor}
\Verb|FileToTableInterpreterExecutor| is implemented in \Verb|libs/extensions/tabular/exec/src/lib/file-to-table-interpreter-executor.ts|.

\Verb|colsAndSchema| returns a list of column names and a map from those column names to a Polars' DataType.
The method reuses code from \Verb|TableInterpreterExecutor| and \Verb|toPolarsDataTypeWithLogs|.
- reuse code from tableInterpreter
\begin{listing}
	\begin{minted}{python}
def colsAndSchema(context):
	valueTypeAssignments = context.get('columns')
	columnDefinitionEntries = TableInterpreter.deriveColumnDefnitionEntriesWithoutHeader(valueTypeAssignments, context)
	schema = {}  # Empty map
	columnNames = []  # Empty list
	for columnDefinition in columnDefinitionEntries:
		# imported from table-interpreter-executor.ts
		schema[columnDefinition.columnName] = toPolarsDataTypeWithLogs(columnDefinition.valueType, context.logger)
		columnNames.add(columnDefinition.columnName)

	return {
		columnNames: columnNames,
		schema: schema,
	}
end
	\end{minted}
\end{listing}

\Verb|csvOptions| to return a \Verb|ReadCSVOptions| object.
This object can be passed to Polars' \Verb|readCSV| and contains configuration on how to parse the \ac{CSV}.
This includes:
\begin{itemize}
	\item \emph{schema}, obtained by calling \Verb|colsAndSchema|.
	\item \emph{header}, \emph{delimiter}, \emph{delimiter} and \emph{enclosing}.
	\item \emph{encoding}, anything other than UTF-8 emits an error message, because it's not supported by Polars.
\end{itemize}

\Verb|doExecute| calls \Verb|csvOptions| to obtain a \Verb|ReadCSVOptions| object, which is then passed to \Verb|polars.readCSV|.

\Verb|constructAndValidateTable| creates a \Verb|PolarsTable| object by calling \Verb|polars.readCSV| and passing the returned \Verb|DataFrame| to the \Verb|PolarsTable| constructor.

\section{LocalFileToTableIntepreter}
\Verb|doExecute| checks if the \Verb|filePath| property contains \Verb|'..'| to prevent path traversal upward and remain consistent with \Verb|LocalFileExtractorExecutor|.

\section{TableTransformer}

\subsection{PolarsTableTransformer}
In Jayvee, a transforms input variable names may differ from the column names of the input table.
Additionaly, the input variables may define ValueTypes that are incompatible with the columns of the input table.
The \Verb|checkInputColumnsMatchTransformInputTypes| method verifies that these ValueTypes are compatible and links each transform input variable name to a Polars column expression.
When applied to a \Verb|DataFrame| the \Verb|pl.col(name)| expression allows us to transform the values of column \Verb|name| \autocite{polars:docs:expr:col}.
\ref{lst:polarstabletransformer:check} contains a pseudocode description of this method.
\begin{listing}
	\begin{minted}{python}
def checkInputColumnsMatchTransformTypes(inputColumnNames, inputTable, transformInputDetailsList):
	indexes = range from 0 to inputColumnNames.length
	variableToColumnMap = {} # Empty map
	for i in indexes:
		inputColumName = inputColumnNames[i]
		inputColumn = inputTable.getColumn(inputColumnName)
		inputDetails = transformInputDetailsList[i]

		if (
			not inputColumn.valueType.isConvertibleTo(inputDetails.valueType)
		) {
			return Error
		}
		variableName = inputDetails.name
		variableToColumnMap.set(variableName, pl.col(inputColumn.name))

	return variableToColumnMap
	\end{minted}
	\caption{}
	\label{lst:polarstabletransformer:check}
\end{listing}

\Verb|doExecute| is described by pseudocode in \ref{lst:polarstabletransformer:execute}.
\begin{listing}
	\begin{minted}{python}
def doExecute(inputTable, context):
	inputColumnNames = context.get('inputColumns')
	outputColumnName = context.get('outputColumn')
	tranformDefinition = context.get('uses')

	inputTable.hasColumns(inputColumnNames)

	transformExecutor = new TransformExecutor(transformDefinition, context)

	transformInputDetails = transformExecutor.getInputDetails()
	variablesToColumns =
		this.checkInputVariablesMatchTransformTypes(
			inputColumnNames,
			inputTable,
			transformInputDetails
		)

	expression =
		transformExecutor.executeTransform(
			variablesToColumns,
			context
		)

	# This adds the `alias` operation to the expression.
	# It will rename the column to `outputColumnName`
	expression = expression.alias(outputColumnName)

	newTable = inputTable.withColumnFromInternal(expression)
	return newTable
	\end{minted}
	\caption{}
	\label{lst:polarstabletransformer:execute}
\end{listing}



\section{TransformExecutor}
\label{section:impl:transforms}
Originally, \Verb|TransformExecutor| would compute the new column by following the algorithm outlined in \ref{lst:old_eval}.


\begin{listing}
	\begin{minted}{python}
newColumn = []  # Empty list
for row in inputColumns:
	...  # add row to evaluation context
	let value = evaluateExpression(expression, context)
	newColumn.add(newColumn)
	...  # remove row from evaluation context
return newColumn
	\end{minted}
	\caption{Pseudocode of the algorithm the interpreter used to execute transforms}
	\label{lst:old_eval}
\end{listing}


Transform executors are implemented in \Verb|lib/execution/src/lib/transforms/transform-executor.ts|.

As explained in \ref{section:transforms} we will use Polars expressions to execute transforms.

\subsection{PolarsTransformExecutor}
\Verb|addInputColumnsToContext| adds the polars expressions, that represent the input columns, to the evaluation context.
The \Verb|EvaluationContext| class contains a map, \Verb|variableValues|, linking variable names to their values of type \Verb{InternalValueRepresentation | pl.Expr}.
\Verb|pl.Expr| is the type for polars expressions.
\Verb|addInputColumnsToContext| uses \Verb|EvaluationContext|'s \Verb|setValueForReference| method to add the polars expressions representing the input columns to the evaluation context.

\Verb|executeTransform| is not overwritten by this class, because it only modifies/changes %FIXME pick one
the context and leaves the other functionality to \Verb|doExecute| (see \ref{lst:polarstransforms:execute}).
\ref{fig:uml:transform} contains a visualization of the calls between \Verb|PolarsTableTransformerExecutor| and \Verb|PolarsTransformExecutor|.
\begin{listing}
	\begin{minted}{python}
def doExecuteTransform(variableToColumnName, context):
	inputDetails = this.getInputDetails()
	outputDetails = this.getOutputDetails()
	this.addInputColumnsToContext(
		inputDetails,
		variableToColumnName,
		context.evaluationContext
	)

	try:
		expr = polarsEvaluateExpression(
			this.getOutputAssignment().expression,
			context.evaluationContext
		)
	except Error:
		return

	targetPolarsDataType = outputDetails.valueType.toPolarsDataType()

	# This casts the type of the resulting column to the type defined for the output.
	# If this conversion is not possible, the program crashes %FIXME rethink this
	expr = expr.cast(targetPolarsDataType)

	return expr
end
	\end{minted}
	\caption{}
	\label{lst:polarstransforms:execute}
\end{listing}
\begin{figure}
	\begin{plantuml}
		@startuml
		autoactivate on
		->":PolarsTableTransformerExecutor": execute(inputTable, context)
		":PolarsTableTransformerExecutor" -> ":PolarsTransformExecutor": executeTransform(\ncolumns,\ncontext\n)
		":PolarsTransformExecutor" ->]: polarsEvaluateExpression(\njayvee expression\n)
		return expr: pl.Expr
		return expr.cast(pl.f64)
		return inputTable.withColumnFromInternal(\nexpr.cast(pl.f64).alias('out')\n)
		@enduml
	\end{plantuml}
	\caption{Sequence diagram of the mehtod calls between \Verb{PolarsTableTransformerExecutor} and \Verb{PolarsTransformExecutor}}
	\label{fig:uml:transform}
\end{figure}

\subsection{Expressions}
\textcite{polars:docs:expr} seperate Jayvee expression into three categories: \emph{literals}, \emph{variables}, \emph{operators}.
The \Verb|polarsEvaluateExpression| function, located in \Verb|libs/language-server/src/lib/ast/expressions/evaluate-expression.ts|, evaluates Jayvee expressions depending on this category (see \ref{fig:uml:polars_evaluate_expression}).

\begin{figure}
	\begin{plantuml}
		@startuml
		start
		if (expr is a variable) then (yes)
		:retrieve the value of expr from context;
		if (value has type InternalValueRepresentation) then (yes)
		:return pl.lit(value);
		stop
		else (no)
		:return value;
		stop
		endif
		elseif (expr is a literal) then (yes)
		:evaluate the value of expr;
		if (value === undefined) then (true)
		:return undefined;
		stop
		else (false)
		:return pl.lit(value);
		stop
		endif
		else (expr is an operator)
		:obtain the fitting operator
		evaluator;
		:evaluate the Jayvee expression
		to a polars expression;
		:return the polars expresion;
		stop
		endif
		@enduml
	\end{plantuml}
	\caption{
		Activity diagram of the \Verb{polarsEvaluateExpression} function.
		\Verb{expr} is the expression that should be evaluated. %FIXME: caption
	}
	\label{fig:uml:polars_evaluate_expression}
\end{figure}


\subsubsection{Operator evaluators}
\label{subsubsection:impl:operator_evaluator}
Operator Evaluators are used by \Verb|polarsEvaluateExpressions| to transfrom a Jayvee operator into a Polars expression.

- polarsEvaluate


\begin{listing}
	\begin{minted}{typescript}
class MultiplicationOperatorEvaluator extends DefaultBinaryOperatorEvaluator<
  number,
  number,
  number
> {
  constructor() {
    super('*', NUMBER_TYPEGUARD, NUMBER_TYPEGUARD);
  }
  override doEvaluate(leftValue: number, rightValue: number): number {
    return leftValue * rightValue;
  }
  override polarsDoEvaluate(
    left: PolarsInternal,
    right: PolarsInternal,
  ): pl.Expr {
    return left.mul(right);
  }
}
	\end{minted}

\end{listing}





- Operator type calculators were not changed
- they dont reflect the actual types of the data during runtime anymore.
- they still prevent the user from doing illegal stuff.


\subsubsection{example}
- imagune a jayvee pipeline containing this tabletransformer \
\begin{minted}{typescript}
	transform tr {
		from x oftype integer;
		from y oftype integer;
		to z oftype decimal;
		z: x * 2 + y;
	}
	block Bl oftype TableTransformer {
		inputColumns: ['a', 'b'];
		outputColumn: 'c';
		uses: tr;
	}
\end{minted}
- how he inputTable to Bl is transformed is depicted in this diagram
\begin{figure}
	\begin{plantuml}
		@startuml
		autoactivate on
		->":PolarsTableTransformerExecutor": execute(inputTable, transform)
		":PolarsTableTransformerExecutor" -> ":PolarsTransformExecutor": executeTransform({\nx: pl.col('a'),\ny: pl.col('b')\n})
		":PolarsTransformExecutor" -> ":EvaluationContext": map x to pl.col('a')
		return
		":PolarsTransformExecutor" -> ":EvaluationContext": map y to pl.col('b')
		return		":PolarsTransformExecutor" -> ":AdditionOperatorEvaluator": evaluate x + y
		":AdditionOperatorEvaluator" -> ":EvaluationContext": get x
		return pl.col('a')
		":AdditionOperatorEvaluator" -> ":EvaluationContext": get y
		return pl.col('b')
		return pl.col('a')\n.add(pl.col('b'))
		return pl.col('a')\n.add(pl.col('b'))\n.cast(pl.f64)
		return Table with column generated by\npl.col('a')\n.add(pl.col('b'))\n.cast(pl.f64)\n.alias('c')
		@enduml
	\end{plantuml}
	\caption{}
	\label{fig:uml:epr:example}
\end{figure}




\section{SQLiteLoader}
- doExecute
- retrieve file, table and dropTable properties from context
- call executeLoad

- executeLoad
- general implementation for both Ts and Polars.
- uses generateInsertTableStatement and generateCreateTableStatement from Table class, which have different implementations for polars and ts (see those sections)

- \Verb|PolarsSQLiteLoaderExecutor| and \Verb|TsSQLLoader| don't override the default implementation

\subsection{sqlite-loader-rust}
\label{subsection:sqlite-loader-rust}

\subsubsection{Napi-rs}
- napi-rs allows us to compile a rust library to a .node file
- nodejs can load and use this .node file
- the types that can be passed to this function is restricted by napi.rs capabilites

- we want to evaluate the extensibility of the polars backend
- create a extenal rust library with typescript interface via napi-package-template: \Verb|sqlite-loader-rust|
- napi function cannot have dataframe as a parameter: type is too complex for napi
- Solution: export dataframe into an arrow ipc file on disk. then
- call \Verb|loadSqlite|
- negative: context (including the logger, is lost)

\subsubsection{Ecosystem overview}
- rusqlite: no arrow support, but works well, can write
- arrow\_adbc: rust implementation is not there yet, it only has a dummy driver (not sqlite or postgres), requires dynamic linking of c libraries,
- connector\_arrow: built in rust, uses the arrow crate under the hood, supports many backends (postgres, duckdb, etc.), only sqlite implemented because prototype. WE USE THIS

\subsubsection{impl}
- in case of unrecoverable error, use napi's errors to throw an error in the typescript code. include messages by library errors.
- biggest reason for linecount and complexity is error handling

- ipcReader
- opens a file and wrape it in an arrow file reader
- use arrow::FileReader to read the ipc file into a BatchRecord iterator, because tables can be comprised of multiple batchrecords

- pop_first_batch: remove the first batch read from the iterator

- db_connection
- create a connection to a sqlite database using rusqlite
- wrap that connection with connector\_arrow's SQLiteConnection type
- can now write arrow data to this connection

- append: see listing
\begin{listing}
	\begin{minted}{lua}
function append(appender, first_batch, remainder)
	inserted_rows = 0
	remainder.prepend(first_batch)
	for batch in remainder do
		appender.append(batch)
		inserted_rows += batch.number_of_rows
	end
	return inserted_rows
end
	\end{minted}
\end{listing}

- load\_sqlite
\begin{listing}
	\begin{minted}{lua}
function load_sqlite(ipc_path, table_name, sqlite_path, drop_table)
	reader = ipc_reader()
	conn = db_connection(sqlite_path)

	if drop_table then
		conn.table_drop(table_name)
	endif

	schema = reader.schema()
	appender = conn.append(table_name)
	inserted_rows = append(appender, reader)
end
	\end{minted}
\end{listing}

